{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.optim as optim \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "\n",
    "from models import NN\n",
    "from compute_score import compute_score\n",
    "\n",
    "DEVICE=\"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose([\n",
    "                    ToTensor(),\n",
    "                    Normalize((0.1307,), (0.3081,))\n",
    "                    ])\n",
    "\n",
    "trainset = MNIST(root=\"../../../coding/Dataset/\", train=True, download=False, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=256, shuffle=True)\n",
    "\n",
    "class_to_data = {i:[] for i in range(10)}\n",
    "\n",
    "for data, label in trainset:\n",
    "    class_to_data[label].append(data)\n",
    "\n",
    "for class_label in class_to_data:\n",
    "    class_to_data[class_label] = torch.stack(class_to_data[class_label]).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden Layer of Size 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_losses_10 = []\n",
    "all_borne_infinie_10 = []\n",
    "all_borne_finie_10 = []\n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"**** model {i} ****\")\n",
    "\n",
    "    model = NN(hidden_dim=10).to(DEVICE)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "    records_loss = []\n",
    "    records_borne_timesteps = []\n",
    "    records_borne_lambda0 = []\n",
    "    records_loss_exp = []\n",
    "\n",
    "    lambda_min_init, classes = compute_score(model, trainset, device=DEVICE)\n",
    "\n",
    "    full_score_init = 0\n",
    "    score_init = []\n",
    "\n",
    "    for c in classes:\n",
    "        score_c = torch.sum((1 - F.softmax(model(class_to_data[c]), dim=1)[:,c])**2)\n",
    "        full_score_init+=score_c\n",
    "    full_score_init/=len(trainset)\n",
    "    borne_init = full_score_init\n",
    "\n",
    "    records_borne_timesteps.append(borne_init.item())\n",
    "    records_borne_lambda0.append(borne_init.item())\n",
    "    records_loss_exp.append(borne_init.item())\n",
    "    \n",
    "    pbar = trange(10)\n",
    "    for epoch in pbar:\n",
    "        model.train()\n",
    "\n",
    "        running_loss = 0\n",
    "        for i, (inputs, targets) in enumerate(trainloader):\n",
    "            preds = model(inputs)\n",
    "            loss = criterion(preds, targets)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss+=loss.item()\n",
    "        pbar.set_description(f\"Epoch : {epoch+1} : loss {running_loss}\")\n",
    "\n",
    "        model.eval()\n",
    "        lambda_min, classes = compute_score(model, trainset)\n",
    "\n",
    "        full_score = 0\n",
    "        borne_timesteps = 0\n",
    "        borne_lambda0 = 0\n",
    "\n",
    "        for c in classes:\n",
    "            score_c = sum((1 - F.softmax(model(class_to_data[c]), dim=1)[:,c])**2)\n",
    "            full_score+=score_c\n",
    "\n",
    "        borne_timesteps = np.exp(-lambda_min*(epoch+1))*full_score_init.detach()\n",
    "        borne_lambda0 = np.exp(-lambda_min_init*(epoch+1))*full_score_init.detach()\n",
    "\n",
    "        full_score = full_score.item()/len(trainset)\n",
    "        records_borne_timesteps.append(borne_timesteps)\n",
    "        records_borne_lambda0.append(borne_lambda0)\n",
    "        records_loss_exp.append(full_score)\n",
    "        records_loss.append(running_loss)\n",
    "\n",
    "    all_losses_10.append(records_loss_exp)\n",
    "    all_borne_finie_10.append(records_borne_timesteps)\n",
    "    all_borne_infinie_10.append(records_borne_lambda0)\n",
    "\n",
    "plt.plot(np.mean(all_losses_10, axis=0), c=\"red\", label=\"train loss\")\n",
    "plt.plot(np.mean(all_borne_finie_10, axis=0), c=\"blue\", label=\"bound $\\lambda_t$\")\n",
    "plt.plot(np.mean(all_borne_infinie_10, axis=0), c=\"green\", label=\"bound $\\lambda_0$\")\n",
    "plt.title('Hidden layer size : 10')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden Layer of Size 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_losses_100 = []\n",
    "all_borne_infinie_100 = []\n",
    "all_borne_finie_100 = []\n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"**** model {i} ****\")\n",
    "\n",
    "    model = NN(hidden_dim=100).to(DEVICE)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "    records_loss = []\n",
    "    records_borne_timesteps = []\n",
    "    records_borne_lambda0 = []\n",
    "    records_loss_exp = []\n",
    "\n",
    "    lambda_min_init, classes = compute_score(model, trainset, device=DEVICE)\n",
    "\n",
    "    full_score_init = 0\n",
    "    score_init = []\n",
    "\n",
    "    for c in classes:\n",
    "        score_c = torch.sum((1 - F.softmax(model(class_to_data[c]), dim=1)[:,c])**2)\n",
    "        full_score_init+=score_c\n",
    "    full_score_init/=len(trainset)\n",
    "    borne_init = full_score_init\n",
    "\n",
    "    records_borne_timesteps.append(borne_init.item())\n",
    "    records_borne_lambda0.append(borne_init.item())\n",
    "    records_loss_exp.append(borne_init.item())\n",
    "    \n",
    "    pbar = trange(10)\n",
    "    for epoch in pbar:\n",
    "        model.train()\n",
    "\n",
    "        running_loss = 0\n",
    "        for i, (inputs, targets) in enumerate(trainloader):\n",
    "            preds = model(inputs)\n",
    "            loss = criterion(preds, targets)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss+=loss.item()\n",
    "        pbar.set_description(f\"Epoch : {epoch+1} : loss {running_loss}\")\n",
    "\n",
    "        model.eval()\n",
    "        lambda_min, classes = compute_score(model, trainset)\n",
    "\n",
    "        full_score = 0\n",
    "        borne_timesteps = 0\n",
    "        borne_lambda0 = 0\n",
    "\n",
    "        for c in classes:\n",
    "            score_c = sum((1 - F.softmax(model(class_to_data[c]), dim=1)[:,c])**2)\n",
    "            full_score+=score_c\n",
    "\n",
    "        borne_timesteps = np.exp(-lambda_min*(epoch+1))*full_score_init.detach()\n",
    "        borne_lambda0 = np.exp(-lambda_min_init*(epoch+1))*full_score_init.detach()\n",
    "\n",
    "        full_score = full_score.item()/len(trainset)\n",
    "        records_borne_timesteps.append(borne_timesteps)\n",
    "        records_borne_lambda0.append(borne_lambda0)\n",
    "        records_loss_exp.append(full_score)\n",
    "        records_loss.append(running_loss)\n",
    "\n",
    "    all_losses_100.append(records_loss_exp)\n",
    "    all_borne_finie_100.append(records_borne_timesteps)\n",
    "    all_borne_infinie_100.append(records_borne_lambda0)\n",
    "\n",
    "plt.plot(np.mean(all_losses_100, axis=0), c=\"red\", label=\"train loss\")\n",
    "plt.plot(np.mean(all_borne_finie_100, axis=0), c=\"blue\", label=\"bound $\\lambda_t$\")\n",
    "plt.plot(np.mean(all_borne_infinie_100, axis=0), c=\"green\", label=\"bound $\\lambda_0$\")\n",
    "plt.title('Hidden layer size : 100')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden Layer of Size 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_losses_1000 = []\n",
    "all_borne_infinie_1000 = []\n",
    "all_borne_finie_1000 = []\n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"**** model {i} ****\")\n",
    "\n",
    "    model = NN(hidden_dim=1000).to(DEVICE)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "    records_loss = []\n",
    "    records_borne_timesteps = []\n",
    "    records_borne_lambda0 = []\n",
    "    records_loss_exp = []\n",
    "\n",
    "    lambda_min_init, classes = compute_score(model, trainset, device=DEVICE)\n",
    "\n",
    "    full_score_init = 0\n",
    "    score_init = []\n",
    "\n",
    "    for c in classes:\n",
    "        score_c = torch.sum((1 - F.softmax(model(class_to_data[c]), dim=1)[:,c])**2)\n",
    "        full_score_init+=score_c\n",
    "    full_score_init/=len(trainset)\n",
    "    borne_init = full_score_init\n",
    "\n",
    "    records_borne_timesteps.append(borne_init.item())\n",
    "    records_borne_lambda0.append(borne_init.item())\n",
    "    records_loss_exp.append(borne_init.item())\n",
    "    \n",
    "    pbar = trange(10)\n",
    "    for epoch in pbar:\n",
    "        model.train()\n",
    "\n",
    "        running_loss = 0\n",
    "        for i, (inputs, targets) in enumerate(trainloader):\n",
    "            preds = model(inputs)\n",
    "            loss = criterion(preds, targets)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss+=loss.item()\n",
    "        pbar.set_description(f\"Epoch : {epoch+1} : loss {running_loss}\")\n",
    "\n",
    "        model.eval()\n",
    "        lambda_min, classes = compute_score(model, trainset)\n",
    "\n",
    "        full_score = 0\n",
    "        borne_timesteps = 0\n",
    "        borne_lambda0 = 0\n",
    "\n",
    "        for c in classes:\n",
    "            score_c = sum((1 - F.softmax(model(class_to_data[c]), dim=1)[:,c])**2)\n",
    "            full_score+=score_c\n",
    "\n",
    "        borne_timesteps = np.exp(-lambda_min*(epoch+1))*full_score_init.detach()\n",
    "        borne_lambda0 = np.exp(-lambda_min_init*(epoch+1))*full_score_init.detach()\n",
    "\n",
    "        full_score = full_score.item()/len(trainset)\n",
    "        records_borne_timesteps.append(borne_timesteps)\n",
    "        records_borne_lambda0.append(borne_lambda0)\n",
    "        records_loss_exp.append(full_score)\n",
    "        records_loss.append(running_loss)\n",
    "\n",
    "    all_losses_1000.append(records_loss_exp)\n",
    "    all_borne_finie_1000.append(records_borne_timesteps)\n",
    "    all_borne_infinie_1000.append(records_borne_lambda0)\n",
    "\n",
    "plt.plot(np.mean(all_losses_1000, axis=0), c=\"red\", label=\"train loss\")\n",
    "plt.plot(np.mean(all_borne_finie_1000, axis=0), c=\"blue\", label=\"bound $\\lambda_t$\")\n",
    "plt.plot(np.mean(all_borne_infinie_1000, axis=0), c=\"green\", label=\"bound $\\lambda_0$\")\n",
    "plt.title('Hidden layer size : 1000')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
